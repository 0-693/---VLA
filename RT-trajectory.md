

## RT-Trajectory 的 Action Head 设计详解

**RT-Trajectory** 是在 RT-1 框架基础上提出的一种新型动作条件建模方式，其核心创新在于使用**人类可绘制的 2D/2.5D 轨迹草图（trajectory sketches）**来替代语言或目标图像作为任务条件。该模型的 Action Head 实质是一个 **基于轨迹图像条件的动作生成网络**，能够理解轨迹草图中位置、时序、交互信号并输出连续控制命令。

---

### 一、核心思想

RT-Trajectory 不再以语言或 token 序列输出动作，而是将**轨迹图像 sketch 与视觉观测一起作为输入**，通过 Transformer 编码处理，输出连续控制向量。

| 输入模态     | 说明                                     |
|--------------|------------------------------------------|
| RGB 图像     | 来自机器人头部摄像头的当前视觉帧         |
| Trajectory Sketch | 人画/系统生成的轨迹图像，标注轨迹、时间、抓取点等信息 |

---

### 二、轨迹编码方式（Trajectory Representation）

RT-Trajectory 中的“Action Head”实际上是通过轨迹 sketch 控制动作预测的系统，具体包括以下编码机制：

#### 两种表示形式：

| 形式            | 包含内容                                           |
|------------------|----------------------------------------------------|
| **RT-Trajectory (2D)**   | 轨迹路径（2D像素轨迹）+ 抓取交互点（interaction markers）       |
| **RT-Trajectory (2.5D)** | 2D轨迹 + 时间通道（红色通道）+ 高度信息（绿色通道）             |

#### 编码方法：

- 轨迹草图绘制于与当前图像相同大小的画布上；
- 利用颜色通道表示附加信息（时间/高度）；
- 抓取开始/释放点通过圆形标记（绿/蓝）表示；
- 所有 sketch 图像被拼接进图像 tokenizer 中的额外输入通道。

---

### 三、动作预测流程（Action Head 模块）

#### 输入构造：
- 使用 EfficientNet-B3 作为图像编码器；
- 将 sketch 与 RGB 图像沿 channel 拼接后送入 Transformer；
- 不使用语言输入，移除 RT-1 中的 FiLM 层；
- 输入为历史 6 帧 RGB + Sketch 图像。

#### 输出形式：
- 模型输出连续动作向量（7-DoF）+ gripper 状态；
- 行为克隆（BC）训练，优化目标为 log-likelihood：
  \[
  \mathcal{L} = -\log p_\theta(a_t \mid x_t, \text{sketch}_t)
  \]

---

### 四、与其他模型对比（Action Head 层面）

| 模型             | Action Head类型              | Token输出 | 轨迹条件 | 是否可解释 | 是否适配高度 |
|------------------|-------------------------------|------------|------------|----------------|----------------|
| RT-1             | 分类器（token分类）           | 是         | 否         | 否             | 否             |
| RT-2             | 自回归token生成 + de-tokenizer| 是         | 否         | 否             | 否             |
| OpenVLA          | Token + 量化映射               | 是         | 否         | 否             | 否             |
| **RT-Trajectory**| **基于图像 sketch 的连续动作生成** | 否         | 是（2D图像） | 是（人类可画） |是（2.5D）      |

---

### 五、设计优势总结

- **人类可解释的 Action Head**：通过图像画线即可控制机器人，无需复杂 prompt；
- **可视提示工程支持**：改变 sketch 提示可引导行为差异（如提高动作精度）；
- **适配多种生成方式**：支持人画、视频估计、LLM 生成代码、VLM 图像生成等；
- **更强任务泛化能力**：在多项 unseen 任务上成功率大幅超过 RT-1 / RT-2；
- **可结合高度信息（2.5D）**：支持高度 disambiguation，提高抓取精度。
